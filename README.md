# Intro To Machine Learning
This contains information from a talk given to the University or Oregon Society of Physics Students (SPS). The Mathematica notebook shows how Gradient Descent works in the context of a 2-dimensional minimization problem. The associated video shows the minimization happening. There are also two versions of the talk (keynote and power point).

## Resources
### Online classes
  * [This class](https://www.coursera.org/learn/machine-learning/home/welcome) is a little older, and does the programming in Octave instead of python, but is a great class. This goes over many techniques beyond neural networks.

  * [An updated version]( https://www.coursera.org/specializations/deep-learning) does things with python and uses some of the standard tools. It focuses more on deep learning.

### Python Packages
 * [Scikit-Learn](http://scikit-learn.org/stable/) makes machine learning very easy.
 * [Keras](https://keras.io) is the package I use for neural networks.

### Datasets and challenges
While there is not necessarily much open data in high energy physics, there is a lot of other data to learn from.
 * [Kaggle](https://www.kaggle.com) hosts many datasets and some challenges. Users upload their scripts, which is a great resource for learning the techniques. In addition, one of the hosted challenges was to [use ATLAS data to find the Higgs](https://www.kaggle.com/c/higgs-boson)!
 * [Data Driven](https://www.drivendata.org) is another site which offers challenges and prizes.
 * [HackerRank](https://www.hackerrank.com) is not necessarily for machine learning, but a great place to practice programming. I highly recommend it. It offers coding challenges for prizes.
 * [CERN open data](http://opendata.cern.ch) I don't have any experience with either of these open data resources, other than knowing they exist.
 * [CMS open data](http://opendata.cern.ch/docs/about-cms)
